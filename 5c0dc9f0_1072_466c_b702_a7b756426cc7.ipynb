{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5c0dc9f0-1072-466c-b702-a7b756426cc7",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imyanzhen/neon/blob/master/5c0dc9f0_1072_466c_b702_a7b756426cc7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "869sa3f5-HcL",
        "colab_type": "code",
        "outputId": "f0e70f0f-6069-4ebc-b6cf-7365f3b27adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import time\n",
        "import nltk\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%load_ext google.colab.data_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF4b7fzkqd0i",
        "colab_type": "code",
        "outputId": "bfe8304b-a1d5-4624-f671-ecd959ddd030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Chen/output1.csv', header=None, names=['text'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Madame Secretary:\\n\\nThank you for reaching out to Secretary Solis and convincing her to join the Verification Commission. She and Ricardo Lagos will make for a very high profile and effective international component of the Commission.\\n\\nWe will meet with her this morning at 10 am to brief her for Tuesday's journey to Honduras. At this point, it appears we have a military aircraft available. The plan is for the U.S. Delegation to depart D.C., stop in Miami to pick up Ricardo Lagos, and arrive in Tegucigalpa together. We think this will send a powerful message to Hondurans and leave no doubt about our commitment to seeing this process through to a successful conclusion.\\n\\nYou should be aware that Ambassador Hugo Llorens is under public assault. The Wall Street Journal dedicates its America's column this morning to attacking him and calling for his removal. Last Friday, Representative Connie Mack did the same. This chorus will grow as the extent of our accomplishment is understood. Llorens is a tough, stalwart guy. He and his Mission have held firm during this crisis. A call from you would be a big boost. Finally, we will hold an IPC today to identify further steps. We will keep you up to date on these steps and identify further opportunities for your engagement.\\n\\nI want to thank you for your leadership and support during this long crisis. Your willingness to engage at key moments and take risks at the right time have propelled us much further than anyone expected. Your diplomacy prevented a debilitating civil conflict in Honduras that would have destabilized Central America and undermined two decades of our efforts. We now have a big opportunity in front of us, and for that we are grateful to you. Regards, Tom\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Cheryl, Jake,\\n\\nI received a call from Masood Ahmed, Director of the Middle East Department at the IMF. Apparently at the Haiti meeting in NYC, the Secretary had a conversation with IMF Managing Director Dominique Strauss-Kahn in which she expressed an interest in meeting with him to discuss the IMF's work in Haiti and other places.\\n\\nA few weeks earlier, apparently she talked briefly with Mr. Ahmed at a meeting about Pakistan, and also expressed an interest in meeting with the IMF to discuss their work.\\n\\nThe Managing Director would be very happy to meet with her. But I think they wanted to know whether she was really interested in meeting, or whether she was being diplomatic and polite. For what it's worth, I think a meeting could be very useful. Someone from Treasury would want to sit in.\\n\\nHow should I respond to them?\\n\\nThanks.\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"We anticipate the release of what are claimed to be several hundred thousand classified State department cables on Sunday night that detail private diplomatic discussions with foreign governments. By its very nature, field reporting to Washington is candid and often incomplete information. It is not an expression of policy, nor does it always shape final policy decisions. Nevertheless, these cables could compromise private discussions with foreign governments and opposition leaders, and when the substance of private conversations is printed on the front pages of newspapers across the world, it can deeply impact not only US foreign policy interests, but those of our allies and friends around the world. To be clear -- such disclosures put at risk our diplomats, intelligence professionals, and people around the world who come to the United States for assistance in promoting democracy and open government. These documents also may include named individuals who in many cases live and work under oppressive regimes and who are trying to create more open and free societies. President Obama supports responsible, accountable, and open government at home and around the world, but this reckless and dangerous action runs counter to that goal. By releasing stolen and classified documents, Wikileaks has put at risk not only the cause of human rights but also the lives and work of these individuals. We condemn in the strongest terms the unauthorized disclosure of classified documents and sensitive national security information.\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Spoke to Ed Levine today to follow up on Friday's briefing, address the few take-backs we owed them, and ask about their timeline for providing us with the resolution of ratification.\\n\\nFirst, Ed said that he thought Friday's briefing accomplished what he had hoped \\u2014 that we were able to exhaust the Committee's questions and address all other outstanding concerns. Right now, the Majority staff is in the process of making final tweaks to a draft resolution of ratification. They expect to march down the hall to the Minority very soon and negotiate with them on the draft text. I expressed our wish to receive the draft resolution before POTUS leaves on his trip on the 18th, to show momentum that Senate consideration is moving forward. Ed said that he expect the Committee to meet that timeline and hopes to provide State with an agreed upon draft resolution by the end of this week/early next week.\\n\\nSecond, I asked if Senator Kerry would consider making some sort of public statement in support of the Treaties prior to the POTUS visit to Australia. He said that was a fair request and he would kick around the idea with his colleagues of inserting a floor statement into the Congressional Record.\\n\\nFinally, I should just mention that Ed stressed twice how much he hoped that once the resolution is provided to the State, that we would be able to agree to most of the text. Obviously, I said that would depend on what it looked like. He understood, but just wanted folks to know that the heavy lifting is occurring in the Committee now (between the Majority and Minority) and once the Committee acts on it, he expects little controversy on the floor.\\n\\nJen\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Purely to update: Tom had me in for lunch at the Mess this past week, ostensibly to discuss my upcoming trip to Georgia, Ukraine, Russia, but in fact to discuss the Our Mutual Friend. It sounded quite ominous re his immediate boss, and not great re the ultimate one. I know OMF had a meeting w/ Tom's immediate boss later, but I do not know what transpired. I'm having dinner w/ OMF tomorrow/Sunday. remain in the same mode as the one you asked me to be in some weeks ago, unless you tell me otherwise.\\n\\nNo need to reply in substance to this message-it's just informational; but I'd appreciate confirmation of receipt. On a more cheerful note, the Times piece turned out very, very well. Hope my Russian friends were there usual charming and helpful selves. Javier Solana and I will be there. in a little over a week. Hi to Bill. S.\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"text\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Madame Secretary:\\n\\nThank you for reaching ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cheryl, Jake,\\n\\nI received a call from Masood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We anticipate the release of what are claimed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spoke to Ed Levine today to follow up on Frida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Purely to update: Tom had me in for lunch at t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Madame Secretary:\\n\\nThank you for reaching ou...\n",
              "1  Cheryl, Jake,\\n\\nI received a call from Masood...\n",
              "2  We anticipate the release of what are claimed ...\n",
              "3  Spoke to Ed Levine today to follow up on Frida...\n",
              "4  Purely to update: Tom had me in for lunch at t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTHDUr3-T8SJ",
        "colab_type": "code",
        "outputId": "e5bf9c0f-240f-4c8c-f9ca-e18038a8ec97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4800, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr69llA_-c26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(x):\n",
        "  return nltk.sent_tokenize(x)\n",
        "\n",
        "def sentenize(temp, col = 'text', reset_index=False):\n",
        "  s = temp.apply(lambda x: pd.Series(x[col]),axis=1).stack().reset_index(level=1, drop=True)\n",
        "  s.name = col\n",
        "  temp = temp.drop(col, axis=1).join(s)\n",
        "  if reset_index:\n",
        "    temp.reset_index(inplace=True)\n",
        "  return temp\n",
        "\n",
        "def lsa_process(df):\n",
        "  temp = df.copy()\n",
        "\n",
        "  temp.loc[:,'text'] = temp.text.apply(lambda x: x.lower())\n",
        "\n",
        "  temp.loc[:,'text'] = temp['text'].apply(tokenize)\n",
        "  temp = sentenize(temp,'text',True)\n",
        "  temp.columns = ['para_id','text']\n",
        "\n",
        "  temp.loc[:,'text'] = temp['text'].apply(lambda x: x.split(':'))\n",
        "  temp = sentenize(temp,'text')\n",
        "\n",
        "  temp.loc[:,'text'] = temp['text'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n",
        "\n",
        "  temp.loc[:,'text'] = temp['text'].dropna()\n",
        "\n",
        "  temp = temp[temp['text'].str.split().str.len().gt(3)]\n",
        "\n",
        "  temp = temp.reset_index(drop=True)\n",
        "\n",
        "  vectorizer = TfidfVectorizer(max_df=0.9, max_features=10000,\n",
        "                             min_df=2, stop_words='english',\n",
        "                             use_idf=True)\n",
        "  \n",
        "  dtm = vectorizer.fit_transform(temp['text'])\n",
        "\n",
        "  # doc_term_matrix = X_train_tfidf.todense()\n",
        "  # pd.DataFrame(doc_term_matrix, columns=vectorizer.get_feature_names(), \\\n",
        "  # index=train_text).head()\n",
        "\n",
        "  lsa = TruncatedSVD(5)\n",
        "  dtm_lsa = make_pipeline(lsa, MinMaxScaler(copy=False),\n",
        "                          Normalizer(copy=False),verbose=True)\n",
        "  dtm_lsa = dtm_lsa.fit_transform(dtm)\n",
        "\n",
        "  # pd.DataFrame(svd.components_, columns = vectorizer.get_feature_names())\n",
        "\n",
        "  # lsa_df = pd.DataFrame(X_train_lsa, index=train_text)\n",
        "  lsa_df = pd.DataFrame(dtm_lsa)\n",
        "  lsa_df.columns = ['dim' + str(col) for col in lsa_df.columns]\n",
        "\n",
        "  for i in range(len(lsa_df)-1):\n",
        "    temp.loc[i,'cosine'] = cosine(lsa_df.iloc[i].values,lsa_df.iloc[i+1].values)\n",
        "\n",
        "  temp['sent_id'] = temp.groupby(['para_id']).cumcount()+1\n",
        "  temp.loc[temp.groupby('para_id')['cosine'].tail(1).index, 'cosine'] = np.nan\n",
        "  temp = temp[['para_id','sent_id','text','cosine']]\n",
        "\n",
        "  final_df = temp.join(lsa_df).rename_axis('sent_gid').reset_index()\n",
        "\n",
        "  xx = final_df.groupby('para_id').agg({'sent_gid':['count'], \n",
        "                                        'cosine':['mean','median','max',\n",
        "                                                  'min','std']})[['sent_gid',\n",
        "                                                                  'cosine']]\n",
        "  xx.columns = [\"_\".join(x) for x in xx.columns.ravel()]\n",
        "  xx['sent_begin'] = final_df.groupby('para_id').head(1).sent_gid.values\n",
        "  xx['sent_end'] = final_df.groupby('para_id').tail(1).sent_gid.values\n",
        "  outdf1 = xx.reset_index()[['para_id','sent_begin','sent_end',\n",
        "                             'sent_gid_count','cosine_mean',\n",
        "                            'cosine_median','cosine_max',\n",
        "                             'cosine_min','cosine_std']]\n",
        "  outdf1.columns = ['paragraph_id','sentence_begin','sentence_end',\n",
        "                    'sentence_count','cosine_mean',\n",
        "                'cosine_median','cosine_max','cosine_min','cosine_std']\n",
        "\n",
        "  outdf2 = final_df[['sent_gid','text','dim0','dim1','dim2','dim3','dim4']]\n",
        "  outdf2.columns = [['sentence_id','sentence','dimension1','dimension2',\n",
        "                     'dimension3','dimension4','dimension5']]\n",
        "\n",
        "  outdf3 = final_df[['sent_gid','cosine']]\n",
        "  outdf3.columns = ['sentence_id1','cosine']\n",
        "  outdf3['sentence_id2'] = outdf3['sentence_id1']+1\n",
        "  outdf3.dropna(inplace=True)\n",
        "  outdf3 = outdf3[['sentence_id1','sentence_id2','cosine']]\n",
        "\n",
        "  return outdf1,outdf2,outdf3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs40_3MHvYci",
        "colab_type": "code",
        "outputId": "0acfcfcc-f565-47ff-e9a9-8ac0ecdcf576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out1,out2,out3 = lsa_process(df[:1200])\n",
        "out1.to_csv('out1_part1_delv1.csv')\n",
        "out2.to_csv('out1_part1_delv2.csv')\n",
        "out3.to_csv('out1_part1_delv3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ...... (step 1 of 3) Processing truncatedsvd, total=   0.1s\n",
            "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing normalizer, total=   0.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gS3Cq5AfOi",
        "colab_type": "code",
        "outputId": "6d80e9b8-4daf-41a9-856f-7fd963fdea19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out1,out2,out3 = lsa_process(df[1200:2400])\n",
        "out1.to_csv('out1_part2_delv1.csv')\n",
        "out2.to_csv('out1_part2_delv2.csv')\n",
        "out3.to_csv('out1_part2_delv3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ...... (step 1 of 3) Processing truncatedsvd, total=   0.1s\n",
            "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing normalizer, total=   0.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6mCLj2ECwHQ",
        "colab_type": "code",
        "outputId": "23965945-41ff-4f6d-eae0-ce4cb38041b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out1,out2,out3 = lsa_process(df[2400:3600])\n",
        "out1.to_csv('out1_part3_delv1.csv')\n",
        "out2.to_csv('out1_part3_delv2.csv')\n",
        "out3.to_csv('out1_part3_delv3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ...... (step 1 of 3) Processing truncatedsvd, total=   0.1s\n",
            "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing normalizer, total=   0.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_rN7e2EC10E",
        "colab_type": "code",
        "outputId": "ce009ef5-c71a-4185-98a8-365673f66fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out1,out2,out3 = lsa_process(df[3600:])\n",
        "out1.to_csv('out1_part4_delv1.csv')\n",
        "out2.to_csv('out1_part4_delv2.csv')\n",
        "out3.to_csv('out1_part4_delv3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ...... (step 1 of 3) Processing truncatedsvd, total=   0.1s\n",
            "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing normalizer, total=   0.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o775RoIFAvH",
        "colab_type": "code",
        "outputId": "a5a062a8-3f84-40c5-9615-f78cb536bcc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df2 = pd.read_csv('/content/drive/My Drive/Chen/output2.csv', \n",
        "                 header=None, sep='\\t',names=['text'])\n",
        "out1,out2,out3 = lsa_process(df2)\n",
        "out1.to_csv('out2_delv1.csv')\n",
        "out2.to_csv('out2_delv2.csv')\n",
        "out3.to_csv('out2_delv3.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ...... (step 1 of 3) Processing truncatedsvd, total=   0.0s\n",
            "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing normalizer, total=   0.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYiSSE7pyI1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/*.csv '/content/drive/My Drive/Chen/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTD5wRGKy2az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}